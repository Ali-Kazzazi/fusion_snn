{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from pprint import pprint\n",
    "import pickle \n",
    "from scipy import io\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 5000\n",
    "n_test = 1000\n",
    "\n",
    "train, test = chainer.datasets.get_mnist()\n",
    "\n",
    "y_train = np.array([train[i][1] for i in range(n_train)])\n",
    "\n",
    "selected_epoch = 15\n",
    "\n",
    "X_train = np.load(\"./results/train_features\"+str(selected_epoch)+\".npy\")\n",
    "X_test = np.load(\"./results/features_test_epoch\"+str(selected_epoch)+\".npy\")[:n_test]\n",
    "y_train = np.array([train[i][1] for i in range(n_train)])\n",
    "y_test = np.array([test[i][1] for i in range(n_test)])\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define individual classifiers\n",
    "clf_svc = SVC(\n",
    "    C=1,\n",
    "    kernel='linear',\n",
    "    gamma='scale',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "clf_svc_p = SVC(\n",
    "    C=1,\n",
    "    kernel='linear',\n",
    "    gamma='scale',\n",
    "    random_state=42,\n",
    "    probability=True\n",
    "    \n",
    ")\n",
    "\n",
    "clf_xgb = XGBClassifier(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.2,\n",
    "    n_estimators=200,\n",
    "    eval_metric=\"mlogloss\",\n",
    ")\n",
    "\n",
    "clf_knn = KNeighborsClassifier(\n",
    "    n_neighbors=7,\n",
    "    weights='uniform',\n",
    "    metric='manhattan',\n",
    ")\n",
    "\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    max_depth=None,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "clf_bag = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    n_estimators=100,\n",
    "    max_samples=1.0,\n",
    "    max_features=0.5,\n",
    "    bootstrap=False,\n",
    "    bootstrap_features=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "clf_lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "clf_mnb = MultinomialNB()\n",
    "\n",
    "clf_gb = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"svc\": clf_svc,\n",
    "    \"xgb\": clf_xgb,\n",
    "    \"knn\": clf_knn,\n",
    "    \"rf\": clf_rf,\n",
    "    \"bag\": clf_bag,\n",
    "    \"lda\": clf_lda,\n",
    "    \"mnb\": clf_mnb,\n",
    "    \"gb\": clf_gb,\n",
    "}\n",
    "\n",
    "classifiers_p = {\n",
    "    \"svc_p\": clf_svc_p,\n",
    "    \"xgb\": clf_xgb,\n",
    "    \"knn\": clf_knn,\n",
    "    \"rf\": clf_rf,\n",
    "    \"bag\": clf_bag,\n",
    "    \"lda\": clf_lda,\n",
    "    \"mnb\": clf_mnb,\n",
    "    \"gb\": clf_gb,\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Train classifiers on non-normalized data\n",
    "for name, clf in classifiers.items():\n",
    "        clf.fit(X_train, y_train)  # Train the classifier\n",
    "        predictions = clf.predict(X_test)  # Make predictions\n",
    "        accuracy = accuracy_score(y_test, predictions)  # Compute accuracy\n",
    "        rep = classification_report(y_test, predictions)\n",
    "        results[name] = name + \" \" + str(accuracy) + \"\\n\" + rep\n",
    "        # with open(f\"./reports/rep_{name}.txt\", \"w\") as f:\n",
    "        #         f.write(results[name])\n",
    "        print(name, accuracy, \" DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def make_decision_profiles(X, classifiers_pool):\n",
    "    return np.concatenate(\n",
    "        np.array([clf.predict_proba(X) for clf in classifiers_pool]), axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "def make_decision_templates(decision_profiles, y):\n",
    "    labels = np.unique(y)\n",
    "    decision_templates = np.array(\n",
    "        [decision_profiles[y == _].mean(axis=0) for _ in labels]\n",
    "    )\n",
    "    return decision_templates, labels\n",
    "\n",
    "\n",
    "class DecisionTemplatesClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimators):\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.classifiers_pool_ = self.estimators\n",
    "\n",
    "        [clf.fit(X, y) for clf in self.classifiers_pool_]\n",
    "\n",
    "        dp = make_decision_profiles(X, self.classifiers_pool_)\n",
    "        self.decision_templates_, self.decision_templates_classes_ = (\n",
    "            make_decision_templates(dp, y)\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(\n",
    "            self,\n",
    "            [\n",
    "                \"classes_\",\n",
    "                \"classifiers_pool_\",\n",
    "                \"decision_templates_\",\n",
    "                \"decision_templates_classes_\",\n",
    "            ],\n",
    "        )\n",
    "        X = check_array(X)\n",
    "\n",
    "        dp = make_decision_profiles(X, self.classifiers_pool_)\n",
    "        distances = np.array(\n",
    "            [np.linalg.norm(x - dp, axis=1) for x in self.decision_templates_]\n",
    "        )\n",
    "\n",
    "        return self.decision_templates_classes_.take(np.argmin(distances, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatores = [clf for _, clf in classifiers_p.items()]\n",
    "\n",
    "dt_clf = DecisionTemplatesClassifier(estimatores)\n",
    "\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "print(dt_clf.score(X_test, y_test))\n",
    "rep = classification_report(y_test, dt_clf.predict(X_test))\n",
    "name = \"DecisionTemplatesClassifier\" + \" \" + str(accuracy_score(y_test, dt_clf.predict(X_test))) + \"\\n\" + rep\n",
    "# with open(f\"./reports/rep_DecisionTemplatesClassifier.txt\", \"w\") as f:\n",
    "#     f.write(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
